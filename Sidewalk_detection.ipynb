{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "FV7QBfOT_LT2",
    "outputId": "e66eae8a-9791-4bdf-8e19-d6aa6348e4df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Reshape, Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import imutils\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef data_gen(img_folder, mask_folder):\\n    n = os.listdir(img_folder) #List of training images\\n    random.shuffle(n)\\n    \\n    print(n)\\n    \\n    img = np.zeros(50, 360, 640, 1).astype('float')\\n    mask = np.zeros(50, 360, 640, 1).astype('float')\\n    print(img,mask)\\n    for i in range(0, 50): #initially from 0 to 16, c = 0. \\n        \\n        train_img = cv2.imread(img_folder+n[i])/255.\\n        train_img =  cv2.resize(train_img, (360, 640))# Read an image from folder and resize\\n      \\n        img[i] = train_img #add to array - img[0], img[1], and so on.\\n        \\n        print(img[i])\\n        \\n        train_mask = cv2.imread(mask_folder+n[i], cv2.IMREAD_GRAYSCALE)/255.\\n        train_mask = cv2.resize(train_mask, (360, 640))\\n        train_mask = train_mask.reshape(360, 640, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\\n\\n        mask[i] = train_mask\\n    \\n    yield img, mask\\n    \\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = 'D:\\Project\\AR dataset/'\n",
    "FRAME_PATH = DATA_PATH+'/Raw_data/'\n",
    "MASK_PATH = DATA_PATH+'/Label_data/'\n",
    "\n",
    "train_frame_path = DATA_PATH+'/train_frames/'\n",
    "train_mask_path = DATA_PATH+'/train_masks/'\n",
    "\n",
    "val_frame_path = DATA_PATH+'/val_frames/'\n",
    "val_mask_path = DATA_PATH+'/val_masks/'\n",
    "\n",
    "img_path = os.listdir(train_frame_path)\n",
    "mask_path = os.listdir(train_mask_path)\n",
    "random.shuffle(img_path)\n",
    "random.shuffle(mask_path)\n",
    "\n",
    "train_img = np.zeros((50, 640, 360, 3)).astype('float')\n",
    "train_mask = np.zeros((50, 640, 360, 1)).astype('float')\n",
    "\n",
    "for i in range(0, 50): #initially from 0 to 16, c = 0. \n",
    "        \n",
    "    train_img1 = cv2.imread(train_frame_path+img_path[i])/255.\n",
    "    \n",
    "    if train_img1.shape != (1920,1080,3): \n",
    "        train_img1 = imutils.rotate_bound(train_img1, 90)\n",
    "        \n",
    "    train_img1 =  cv2.resize(train_img1, (360, 640))# Read an image from folder and resize\n",
    "    train_img[i] = train_img1 #add to array - img[0], img[1], and so on.\n",
    "        \n",
    "    train_mask1 = cv2.imread(train_mask_path+mask_path[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "    if train_mask1.shape != (1920,1080,3): train_mask1 = imutils.rotate_bound(train_mask1, 90)\n",
    "\n",
    "    train_mask1 = cv2.resize(train_mask1, (360, 640))\n",
    "\n",
    "    train_mask1 = train_mask1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "\n",
    "    train_mask[i] = train_mask1\n",
    "    \n",
    "# Validation set\n",
    "    \n",
    "img_path = os.listdir(val_frame_path)\n",
    "mask_path = os.listdir(val_mask_path)\n",
    "val_img = np.zeros((10, 640, 360, 3)).astype('float')\n",
    "val_mask = np.zeros((10, 640, 360, 1)).astype('float')\n",
    "\n",
    "for i in range(0, 10): #initially from 0 to 16, c = 0. \n",
    "        \n",
    "    val_img1 = cv2.imread(val_frame_path+img_path[i])/255.\n",
    "    \n",
    "    if val_img1.shape != (1920,1080,3): \n",
    "        val_img1 = imutils.rotate_bound(val_img1, 90)\n",
    "        \n",
    "    val_img1 =  cv2.resize(val_img1, (360, 640))# Read an image from folder and resize\n",
    "    val_img[i] = val_img1 #add to array - img[0], img[1], and so on.\n",
    "        \n",
    "    val_mask1 = cv2.imread(val_mask_path+mask_path[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "    if val_mask1.shape != (1920,1080,3): val_mask1 = imutils.rotate_bound(val_mask1, 90)\n",
    "\n",
    "    val_mask1 = cv2.resize(val_mask1, (360, 640))\n",
    "\n",
    "    val_mask1 = val_mask1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "\n",
    "    val_mask[i] = val_mask1\n",
    "    \n",
    "'''\n",
    "def data_gen(img_folder, mask_folder):\n",
    "    n = os.listdir(img_folder) #List of training images\n",
    "    random.shuffle(n)\n",
    "    \n",
    "    print(n)\n",
    "    \n",
    "    img = np.zeros(50, 360, 640, 1).astype('float')\n",
    "    mask = np.zeros(50, 360, 640, 1).astype('float')\n",
    "    print(img,mask)\n",
    "    for i in range(0, 50): #initially from 0 to 16, c = 0. \n",
    "        \n",
    "        train_img = cv2.imread(img_folder+n[i])/255.\n",
    "        train_img =  cv2.resize(train_img, (360, 640))# Read an image from folder and resize\n",
    "      \n",
    "        img[i] = train_img #add to array - img[0], img[1], and so on.\n",
    "        \n",
    "        print(img[i])\n",
    "        \n",
    "        train_mask = cv2.imread(mask_folder+n[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "        train_mask = cv2.resize(train_mask, (360, 640))\n",
    "        train_mask = train_mask.reshape(360, 640, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "\n",
    "        mask[i] = train_mask\n",
    "    \n",
    "    yield img, mask\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_TRAINING_IMAGES = 50\n",
    "NO_OF_VAL_IMAGES = 10\n",
    "\n",
    "NO_OF_EPOCHS = 5\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "weights_path = DATA_PATH + '/weight/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcDAqCvY4N_n"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#1st Layer\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(360, 640, 1)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(32, (2, 2), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "#1st Layer\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "#1st Layer\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "#1st Layer\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "#Upsampling Part\n",
    "model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 6), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Conv2D(64, (17, 6), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 3)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(128,128,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "jbYonz1M8oeA",
    "outputId": "c9bf0f63-7349-4bfa-9eff-e117f8165058",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 624, 351, 64)      32704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 624, 351, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 608, 342, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 608, 342, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 304, 171, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 288, 162, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 288, 162, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 272, 153, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 272, 153, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 136, 76, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 120, 67, 64)       696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 120, 67, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 104, 58, 64)       696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 104, 58, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 52, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 104, 58, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 88, 49, 64)        696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 88, 49, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 40, 64)        696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 72, 40, 64)        256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 144, 80, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 71, 64)       696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128, 71, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 112, 62, 64)       696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 112, 62, 64)       256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 224, 124, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 208, 115, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 208, 115, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 192, 106, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 192, 106, 64)      256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 384, 212, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 368, 203, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 368, 203, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 352, 194, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 352, 194, 64)      256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 704, 388, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 688, 379, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 688, 379, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 672, 374, 64)      417856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 672, 374, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 656, 365, 64)      696384    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 656, 365, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 640, 360, 64)      417856    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 640, 360, 64)      256       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 640, 360, 1)       65        \n",
      "=================================================================\n",
      "Total params: 11,318,849\n",
      "Trainable params: 11,316,545\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50 samples, validate on 10 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "#model = ResNet50(weights = 'imagenet')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "results = model.fit_generator((train_img,train_mask), epochs = NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          validation_data=(val_img,val_mask), \n",
    "                          validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE), \n",
    "                          callbacks=callbacks_list)\n",
    "'''\n",
    "model.fit(train_img,train_mask,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=NO_OF_EPOCHS,\n",
    "          validation_data=(val_img,val_mask),\n",
    "          verbose=1\n",
    "          )\n",
    "\n",
    "#score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "model.save('Model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BELOW IS UNUSED!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objects': [{'featureId': 'ck6ul3ewo6y6e0z8wg4v2wtyy',\n",
       "   'schemaId': 'ck6t528zygfa70994epxcsaxf',\n",
       "   'title': 'Straight Sidewalk',\n",
       "   'value': 'straight_sidewalk',\n",
       "   'color': '#FF0000',\n",
       "   'instanceURI': 'https://api.labelbox.com/masks/feature/ck6ul3ewo6y6e0z8wg4v2wtyy?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjazV1d3YzNjhsdmhlMGE1NjFmNTdtcndsIiwib3JnYW5pemF0aW9uSWQiOiJjazV1d3YzNW00NGtiMDg2N21tMWprM3MzIiwiaWF0IjoxNTgzNzU5MTA3LCJleHAiOjE1ODYzNTExMDd9.Kj7rLobACybfp55g_zStTtTRbVaxFWRSLksV2WIDBi4'},\n",
       "  {'featureId': 'ck6ul4fjd6ltn10aml6ufzgtq',\n",
       "   'schemaId': 'ck6t528zygfa90994ltuhdp41',\n",
       "   'title': 'Right Sidewalk',\n",
       "   'value': 'right_sidewalk',\n",
       "   'color': '#FFFF00',\n",
       "   'instanceURI': 'https://api.labelbox.com/masks/feature/ck6ul4fjd6ltn10aml6ufzgtq?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjazV1d3YzNjhsdmhlMGE1NjFmNTdtcndsIiwib3JnYW5pemF0aW9uSWQiOiJjazV1d3YzNW00NGtiMDg2N21tMWprM3MzIiwiaWF0IjoxNTgzNzU5MTA3LCJleHAiOjE1ODYzNTExMDd9.Kj7rLobACybfp55g_zStTtTRbVaxFWRSLksV2WIDBi4'},\n",
       "  {'featureId': 'ck6ul4qlu6luc10am6bagk7p2',\n",
       "   'schemaId': 'ck6t528zygfa80994kz0q1nyt',\n",
       "   'title': 'Left Sidewalk',\n",
       "   'value': 'left_sidewalk',\n",
       "   'color': '#FF8000',\n",
       "   'instanceURI': 'https://api.labelbox.com/masks/feature/ck6ul4qlu6luc10am6bagk7p2?token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjazV1d3YzNjhsdmhlMGE1NjFmNTdtcndsIiwib3JnYW5pemF0aW9uSWQiOiJjazV1d3YzNW00NGtiMDg2N21tMWprM3MzIiwiaWF0IjoxNTgzNzU5MTA3LCJleHAiOjE1ODYzNTExMDd9.Kj7rLobACybfp55g_zStTtTRbVaxFWRSLksV2WIDBi4'}],\n",
       " 'classifications': []}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"export-2020-03-09T13_05_07.758Z.json\")\n",
    "data['Label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_range in range(0,len(data)):\n",
    "    raw_data = requests.get(data['Labeled Data'][data_range], stream=True)\n",
    "    \n",
    "    straight_label = (data['Label'][data_range]) \n",
    "    url_straight_label = straight_label['objects'][0]['instanceURI']\n",
    "\n",
    "    label_data = requests.get(url_straight_label, stream=True)\n",
    "    \n",
    "    # Open a local file with wb ( write binary ) permission.\n",
    "    local_raw = open('D:/Project/AR dataset/Raw_data/Raw_%s.jpg' %data_range, 'wb')\n",
    "    local_label = open('D:/Project/AR dataset/Label_data/Label_%s.jpg' %data_range, 'wb')\n",
    "    \n",
    "    # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    raw_data.raw.decode_content = True\n",
    "    label_data.raw.decode_content = True\n",
    "    \n",
    "    # Copy the response stream raw data to local image file.\n",
    "    shutil.copyfileobj(raw_data.raw, local_raw)\n",
    "    shutil.copyfileobj(label_data.raw, local_label)\n",
    "    \n",
    "    # Remove the image url response object.\n",
    "    del raw_data\n",
    "    del label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Label</th>\n",
       "      <th>Created By</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Updated At</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>External ID</th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Benchmark Agreement</th>\n",
       "      <th>Benchmark ID</th>\n",
       "      <th>Benchmark Reference ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>View Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ck6ul4saq4agv0839yzm0d8rg</td>\n",
       "      <td>ck6tb9yrq2gdd0bof3sl5aa9c</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck6ul3ewo6y6e0z8wg...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-02-20T10:10:56.000Z</td>\n",
       "      <td>2020-02-20T10:11:03.000Z</td>\n",
       "      <td>5.004</td>\n",
       "      <td>frame20.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ck6ul76r248uj0952pnf1zxah</td>\n",
       "      <td>ck6tb9yrq2gdp0bof8honbe8s</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck6ul5dq16agx10c6y...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-02-20T10:12:48.000Z</td>\n",
       "      <td>2020-02-20T10:12:54.000Z</td>\n",
       "      <td>111.191</td>\n",
       "      <td>frame23.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ck6ulac2n4e5l0975fc0yx0ym</td>\n",
       "      <td>ck6tb9yrr2ge10bofajdsagd3</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck6ul7rq86b7710c6k...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-02-20T10:15:15.000Z</td>\n",
       "      <td>2020-02-20T10:15:23.000Z</td>\n",
       "      <td>147.220</td>\n",
       "      <td>frame26.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ck6ulhrnr4ezj0952np76z0jp</td>\n",
       "      <td>ck6tb9yrn2gb50bof3irsb6b0</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck6ulhaie77wi0z8w3...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-02-20T10:21:02.000Z</td>\n",
       "      <td>2020-02-20T10:21:08.000Z</td>\n",
       "      <td>90.230</td>\n",
       "      <td>frame0.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ck6ulj5ei4j210975idityuf6</td>\n",
       "      <td>ck6tb9yrn2gbh0bof54eg5x89</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck6uliibf78x90z8wo...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-02-20T10:22:07.000Z</td>\n",
       "      <td>2020-02-20T10:22:12.000Z</td>\n",
       "      <td>63.931</td>\n",
       "      <td>frame3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset0</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>ck7en0obu5uoi0948nwjx0btp</td>\n",
       "      <td>ck6ukzwat3wxi0bofhn8ffrmk</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck7en0i3n0xtw0z7n5...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-03-05T10:59:07.000Z</td>\n",
       "      <td>2020-03-05T10:59:08.000Z</td>\n",
       "      <td>53.379</td>\n",
       "      <td>frame0.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset15</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>ck7en1t3aanwr0918d4v1ui2g</td>\n",
       "      <td>ck6ukzwat3wxu0bofhc005ymm</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck7en1s290xw00z7nq...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-03-05T11:00:00.000Z</td>\n",
       "      <td>2020-03-05T11:00:00.000Z</td>\n",
       "      <td>52.316</td>\n",
       "      <td>frame3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset15</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>ck7en3n0wa8120752qswe392z</td>\n",
       "      <td>ck6ukzwat3wxm0bof7f5i21d5</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck7en3m8z0l73109ic...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-03-05T11:01:26.000Z</td>\n",
       "      <td>2020-03-05T11:01:26.000Z</td>\n",
       "      <td>65.209</td>\n",
       "      <td>frame1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset15</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>ck7en4o595wod0948r7dyl867</td>\n",
       "      <td>ck6ukzwat3wxy0bofayzghanx</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck7en4nt30y2d0z7n3...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-03-05T11:02:14.000Z</td>\n",
       "      <td>2020-03-05T11:02:14.000Z</td>\n",
       "      <td>47.523</td>\n",
       "      <td>frame4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset15</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>ck7en688oa9iy0752eli1i6n3</td>\n",
       "      <td>ck6ukzwat3wxq0bof0jil9d0d</td>\n",
       "      <td>https://storage.labelbox.com/ck5uwv35m44kb0867...</td>\n",
       "      <td>{'objects': [{'featureId': 'ck7en67dk0y6v0z7n0...</td>\n",
       "      <td>magician2120@hotmail.com</td>\n",
       "      <td>Project Bicycle</td>\n",
       "      <td>2020-03-05T11:03:27.000Z</td>\n",
       "      <td>2020-03-05T11:03:27.000Z</td>\n",
       "      <td>72.145</td>\n",
       "      <td>frame2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>ARBicycle_Dataset15</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://editor.labelbox.com?project=ck6rqrabcr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>326 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ID                 DataRow ID  \\\n",
       "0    ck6ul4saq4agv0839yzm0d8rg  ck6tb9yrq2gdd0bof3sl5aa9c   \n",
       "1    ck6ul76r248uj0952pnf1zxah  ck6tb9yrq2gdp0bof8honbe8s   \n",
       "2    ck6ulac2n4e5l0975fc0yx0ym  ck6tb9yrr2ge10bofajdsagd3   \n",
       "3    ck6ulhrnr4ezj0952np76z0jp  ck6tb9yrn2gb50bof3irsb6b0   \n",
       "4    ck6ulj5ei4j210975idityuf6  ck6tb9yrn2gbh0bof54eg5x89   \n",
       "..                         ...                        ...   \n",
       "321  ck7en0obu5uoi0948nwjx0btp  ck6ukzwat3wxi0bofhn8ffrmk   \n",
       "322  ck7en1t3aanwr0918d4v1ui2g  ck6ukzwat3wxu0bofhc005ymm   \n",
       "323  ck7en3n0wa8120752qswe392z  ck6ukzwat3wxm0bof7f5i21d5   \n",
       "324  ck7en4o595wod0948r7dyl867  ck6ukzwat3wxy0bofayzghanx   \n",
       "325  ck7en688oa9iy0752eli1i6n3  ck6ukzwat3wxq0bof0jil9d0d   \n",
       "\n",
       "                                          Labeled Data  \\\n",
       "0    https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "1    https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "2    https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "3    https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "4    https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "..                                                 ...   \n",
       "321  https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "322  https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "323  https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "324  https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "325  https://storage.labelbox.com/ck5uwv35m44kb0867...   \n",
       "\n",
       "                                                 Label  \\\n",
       "0    {'objects': [{'featureId': 'ck6ul3ewo6y6e0z8wg...   \n",
       "1    {'objects': [{'featureId': 'ck6ul5dq16agx10c6y...   \n",
       "2    {'objects': [{'featureId': 'ck6ul7rq86b7710c6k...   \n",
       "3    {'objects': [{'featureId': 'ck6ulhaie77wi0z8w3...   \n",
       "4    {'objects': [{'featureId': 'ck6uliibf78x90z8wo...   \n",
       "..                                                 ...   \n",
       "321  {'objects': [{'featureId': 'ck7en0i3n0xtw0z7n5...   \n",
       "322  {'objects': [{'featureId': 'ck7en1s290xw00z7nq...   \n",
       "323  {'objects': [{'featureId': 'ck7en3m8z0l73109ic...   \n",
       "324  {'objects': [{'featureId': 'ck7en4nt30y2d0z7n3...   \n",
       "325  {'objects': [{'featureId': 'ck7en67dk0y6v0z7n0...   \n",
       "\n",
       "                   Created By     Project Name                Created At  \\\n",
       "0    magician2120@hotmail.com  Project Bicycle  2020-02-20T10:10:56.000Z   \n",
       "1    magician2120@hotmail.com  Project Bicycle  2020-02-20T10:12:48.000Z   \n",
       "2    magician2120@hotmail.com  Project Bicycle  2020-02-20T10:15:15.000Z   \n",
       "3    magician2120@hotmail.com  Project Bicycle  2020-02-20T10:21:02.000Z   \n",
       "4    magician2120@hotmail.com  Project Bicycle  2020-02-20T10:22:07.000Z   \n",
       "..                        ...              ...                       ...   \n",
       "321  magician2120@hotmail.com  Project Bicycle  2020-03-05T10:59:07.000Z   \n",
       "322  magician2120@hotmail.com  Project Bicycle  2020-03-05T11:00:00.000Z   \n",
       "323  magician2120@hotmail.com  Project Bicycle  2020-03-05T11:01:26.000Z   \n",
       "324  magician2120@hotmail.com  Project Bicycle  2020-03-05T11:02:14.000Z   \n",
       "325  magician2120@hotmail.com  Project Bicycle  2020-03-05T11:03:27.000Z   \n",
       "\n",
       "                   Updated At  Seconds to Label  External ID  Agreement  \\\n",
       "0    2020-02-20T10:11:03.000Z             5.004  frame20.jpg        NaN   \n",
       "1    2020-02-20T10:12:54.000Z           111.191  frame23.jpg        NaN   \n",
       "2    2020-02-20T10:15:23.000Z           147.220  frame26.jpg        NaN   \n",
       "3    2020-02-20T10:21:08.000Z            90.230   frame0.jpg        NaN   \n",
       "4    2020-02-20T10:22:12.000Z            63.931   frame3.jpg        NaN   \n",
       "..                        ...               ...          ...        ...   \n",
       "321  2020-03-05T10:59:08.000Z            53.379   frame0.jpg        NaN   \n",
       "322  2020-03-05T11:00:00.000Z            52.316   frame3.jpg        NaN   \n",
       "323  2020-03-05T11:01:26.000Z            65.209   frame1.jpg        NaN   \n",
       "324  2020-03-05T11:02:14.000Z            47.523   frame4.jpg        NaN   \n",
       "325  2020-03-05T11:03:27.000Z            72.145   frame2.jpg        NaN   \n",
       "\n",
       "     Benchmark Agreement  Benchmark ID Benchmark Reference ID  \\\n",
       "0                    NaN           NaN                   None   \n",
       "1                    NaN           NaN                   None   \n",
       "2                    NaN           NaN                   None   \n",
       "3                    NaN           NaN                   None   \n",
       "4                    NaN           NaN                   None   \n",
       "..                   ...           ...                    ...   \n",
       "321                  NaN           NaN                   None   \n",
       "322                  NaN           NaN                   None   \n",
       "323                  NaN           NaN                   None   \n",
       "324                  NaN           NaN                   None   \n",
       "325                  NaN           NaN                   None   \n",
       "\n",
       "            Dataset Name Reviews  \\\n",
       "0     ARBicycle_Dataset0      []   \n",
       "1     ARBicycle_Dataset0      []   \n",
       "2     ARBicycle_Dataset0      []   \n",
       "3     ARBicycle_Dataset0      []   \n",
       "4     ARBicycle_Dataset0      []   \n",
       "..                   ...     ...   \n",
       "321  ARBicycle_Dataset15      []   \n",
       "322  ARBicycle_Dataset15      []   \n",
       "323  ARBicycle_Dataset15      []   \n",
       "324  ARBicycle_Dataset15      []   \n",
       "325  ARBicycle_Dataset15      []   \n",
       "\n",
       "                                            View Label  \n",
       "0    https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "1    https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "2    https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "3    https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "4    https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "..                                                 ...  \n",
       "321  https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "322  https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "323  https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "324  https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "325  https://editor.labelbox.com?project=ck6rqrabcr...  \n",
       "\n",
       "[326 rows x 17 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'D:\\\\Project\\\\AR dataset/train_frames'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5a4818c71019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfolders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'D:\\\\Project\\\\AR dataset/train_frames'"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'D:\\Project\\AR dataset/'\n",
    "FRAME_PATH = DATA_PATH+'/Raw_data/'\n",
    "MASK_PATH = DATA_PATH+'/Label_data/'\n",
    "\n",
    "folders = ['train_frames', 'train_masks', 'val_frames', 'val_masks', 'test_frames', 'test_masks']\n",
    "\n",
    "for folder in folders:\n",
    "    os.makedirs(DATA_PATH + folder)\n",
    "  \n",
    "  \n",
    "# Get all frames and masks, sort them, shuffle them to generate data sets.\n",
    "\n",
    "all_frames = os.listdir(FRAME_PATH)\n",
    "all_masks = os.listdir(MASK_PATH)\n",
    "\n",
    "random.seed(230)\n",
    "random.shuffle(all_frames)\n",
    "\n",
    "\n",
    "# Generate train, val, and test sets for frames\n",
    "\n",
    "train_split = int(0.7*len(all_frames))\n",
    "val_split = int(0.9 * len(all_frames))\n",
    "\n",
    "train_frames = all_frames[:train_split]\n",
    "val_frames = all_frames[train_split:val_split]\n",
    "test_frames = all_frames[val_split:]\n",
    "\n",
    "#Add train, val, test frames and masks to relevant folders\n",
    "\n",
    "def add_frames(dir_name, image):\n",
    "  \n",
    "    img = Image.open(FRAME_PATH+image)\n",
    "    img.save(DATA_PATH+'/{}'.format(dir_name)+'/'+image)\n",
    "    \n",
    "def add_masks(dir_name, image):\n",
    "    \n",
    "    img = Image.open(MASK_PATH+image)\n",
    "    new_image = Image.new(\"RGBA\", img.size, \"BLACK\") # Create a white rgba background\n",
    "    new_image.paste(img, (0, 0), img)              # Paste the image on the background. Go to the links given below for details.\n",
    "    new_image.convert('RGB').save(DATA_PATH+'/{}'.format(dir_name)+'/'+image, \"JPEG\")  # Save as JPEG\n",
    "\n",
    "# Generate corresponding mask lists for masks\n",
    "\n",
    "train_masks = []\n",
    "val_masks = []\n",
    "test_masks = []\n",
    "\n",
    "for f in all_masks:\n",
    "    \n",
    "    name = os.path.basename(MASK_PATH+f)\n",
    "    name = 'Raw_'+name.split('_')[1]\n",
    "    if name in train_frames: train_masks.append(f)\n",
    "for f in all_masks:\n",
    "    \n",
    "    name=os.path.basename(MASK_PATH+f)\n",
    "    name = 'Raw_'+name.split('_')[1]\n",
    "    if name in val_frames: val_masks.append(f)\n",
    "for f in all_masks:\n",
    "    \n",
    "    name = os.path.basename(MASK_PATH+f)\n",
    "    name = 'Raw_'+name.split('_')[1]\n",
    "    if name in test_frames: test_masks.append(f)\n",
    "        \n",
    "frame_folders = [(train_frames, 'train_frames'), (val_frames, 'val_frames'), \n",
    "                 (test_frames, 'test_frames')]\n",
    "\n",
    "mask_folders = [(train_masks, 'train_masks'), (val_masks, 'val_masks'), \n",
    "                (test_masks, 'test_masks')]\n",
    "\n",
    "# Add frames\n",
    "\n",
    "for folder in frame_folders:\n",
    "  \n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "\n",
    "    list(map(add_frames, name, array))\n",
    "         \n",
    "    \n",
    "# Add masks\n",
    "\n",
    "for folder in mask_folders:\n",
    "  \n",
    "    array = folder[0]\n",
    "    name = [folder[1]] * len(array)\n",
    "  \n",
    "    list(map(add_masks, name, array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app\n",
      "['Label_1.jpg', 'Label_10.jpg', 'Label_100.jpg', 'Label_101.jpg', 'Label_102.jpg', 'Label_103.jpg', 'Label_104.jpg', 'Label_107.jpg', 'Label_108.jpg', 'Label_110.jpg', 'Label_111.jpg', 'Label_112.jpg', 'Label_114.jpg', 'Label_116.jpg', 'Label_117.jpg', 'Label_118.jpg', 'Label_12.jpg', 'Label_120.jpg', 'Label_121.jpg', 'Label_124.jpg', 'Label_125.jpg', 'Label_127.jpg', 'Label_129.jpg', 'Label_13.jpg', 'Label_133.jpg', 'Label_134.jpg', 'Label_135.jpg', 'Label_136.jpg', 'Label_137.jpg', 'Label_138.jpg', 'Label_14.jpg', 'Label_140.jpg', 'Label_142.jpg', 'Label_143.jpg', 'Label_144.jpg', 'Label_145.jpg', 'Label_148.jpg', 'Label_15.jpg', 'Label_150.jpg', 'Label_151.jpg', 'Label_153.jpg', 'Label_154.jpg', 'Label_155.jpg', 'Label_156.jpg', 'Label_158.jpg', 'Label_16.jpg', 'Label_160.jpg', 'Label_162.jpg', 'Label_164.jpg', 'Label_166.jpg', 'Label_167.jpg', 'Label_168.jpg', 'Label_169.jpg', 'Label_170.jpg', 'Label_171.jpg', 'Label_173.jpg', 'Label_174.jpg', 'Label_175.jpg', 'Label_176.jpg', 'Label_177.jpg', 'Label_178.jpg', 'Label_18.jpg', 'Label_180.jpg', 'Label_181.jpg', 'Label_182.jpg', 'Label_183.jpg', 'Label_186.jpg', 'Label_187.jpg', 'Label_188.jpg', 'Label_189.jpg', 'Label_19.jpg', 'Label_190.jpg', 'Label_192.jpg', 'Label_193.jpg', 'Label_194.jpg', 'Label_195.jpg', 'Label_196.jpg', 'Label_197.jpg', 'Label_198.jpg', 'Label_199.jpg', 'Label_2.jpg', 'Label_20.jpg', 'Label_202.jpg', 'Label_204.jpg', 'Label_206.jpg', 'Label_207.jpg', 'Label_208.jpg', 'Label_209.jpg', 'Label_210.jpg', 'Label_211.jpg', 'Label_213.jpg', 'Label_214.jpg', 'Label_216.jpg', 'Label_217.jpg', 'Label_218.jpg', 'Label_219.jpg', 'Label_221.jpg', 'Label_222.jpg', 'Label_223.jpg', 'Label_224.jpg', 'Label_225.jpg', 'Label_226.jpg', 'Label_228.jpg', 'Label_229.jpg', 'Label_231.jpg', 'Label_232.jpg', 'Label_233.jpg', 'Label_234.jpg', 'Label_235.jpg', 'Label_236.jpg', 'Label_238.jpg', 'Label_239.jpg', 'Label_24.jpg', 'Label_240.jpg', 'Label_244.jpg', 'Label_245.jpg', 'Label_246.jpg', 'Label_248.jpg', 'Label_249.jpg', 'Label_251.jpg', 'Label_253.jpg', 'Label_254.jpg', 'Label_255.jpg', 'Label_257.jpg', 'Label_258.jpg', 'Label_259.jpg', 'Label_260.jpg', 'Label_261.jpg', 'Label_262.jpg', 'Label_263.jpg', 'Label_267.jpg', 'Label_268.jpg', 'Label_27.jpg', 'Label_270.jpg', 'Label_271.jpg', 'Label_272.jpg', 'Label_273.jpg', 'Label_275.jpg', 'Label_276.jpg', 'Label_278.jpg', 'Label_279.jpg', 'Label_28.jpg', 'Label_282.jpg', 'Label_283.jpg', 'Label_284.jpg', 'Label_285.jpg', 'Label_287.jpg', 'Label_289.jpg', 'Label_29.jpg', 'Label_290.jpg', 'Label_291.jpg', 'Label_292.jpg', 'Label_293.jpg', 'Label_295.jpg', 'Label_296.jpg', 'Label_297.jpg', 'Label_298.jpg', 'Label_3.jpg', 'Label_301.jpg', 'Label_302.jpg', 'Label_305.jpg', 'Label_308.jpg', 'Label_309.jpg', 'Label_31.jpg', 'Label_310.jpg', 'Label_311.jpg', 'Label_312.jpg', 'Label_313.jpg', 'Label_314.jpg', 'Label_315.jpg', 'Label_317.jpg', 'Label_319.jpg', 'Label_320.jpg', 'Label_321.jpg', 'Label_324.jpg', 'Label_35.jpg', 'Label_36.jpg', 'Label_38.jpg', 'Label_40.jpg', 'Label_41.jpg', 'Label_42.jpg', 'Label_43.jpg', 'Label_44.jpg', 'Label_45.jpg', 'Label_46.jpg', 'Label_47.jpg', 'Label_49.jpg', 'Label_5.jpg', 'Label_50.jpg', 'Label_51.jpg', 'Label_53.jpg', 'Label_54.jpg', 'Label_56.jpg', 'Label_57.jpg', 'Label_58.jpg', 'Label_59.jpg', 'Label_6.jpg', 'Label_60.jpg', 'Label_61.jpg', 'Label_63.jpg', 'Label_64.jpg', 'Label_66.jpg', 'Label_67.jpg', 'Label_68.jpg', 'Label_69.jpg', 'Label_70.jpg', 'Label_72.jpg', 'Label_73.jpg', 'Label_75.jpg', 'Label_77.jpg', 'Label_78.jpg', 'Label_79.jpg', 'Label_80.jpg', 'Label_81.jpg', 'Label_82.jpg', 'Label_83.jpg', 'Label_84.jpg', 'Label_85.jpg', 'Label_86.jpg', 'Label_89.jpg', 'Label_9.jpg', 'Label_91.jpg', 'Label_92.jpg', 'Label_94.jpg', 'Label_95.jpg', 'Label_96.jpg', 'Label_97.jpg', 'Label_99.jpg']\n",
      "Label_1.jpg\n",
      "Raw_153.jpg\n"
     ]
    }
   ],
   "source": [
    "print(('apple'.split('l')[0]))\n",
    "print(train_masks)\n",
    "print((train_masks[0]))\n",
    "print((train_frames[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(MASK_PATH+'Label_0.jpg')\n",
    "new_image = Image.new(\"RGBA\", image.size, \"BLACK\") # Create a white rgba background\n",
    "new_image.paste(image, (0, 0), image)              # Paste the image on the background. Go to the links given below for details.\n",
    "new_image.convert('RGB').save('test.jpg', \"JPEG\")  # Save as JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.PngImagePlugin.PngImageFile'>\n"
     ]
    }
   ],
   "source": [
    "png = plt.imread(MASK_PATH+'Label_0.jpg')\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Link for next day: https://towardsdatascience.com/a-keras-pipeline-for-image-segmentation-part-1-6515a421157d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "        \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataGenerator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e9361011e88d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_datagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataGenerator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "DATA_PATH = 'D:\\Project\\AR dataset/'\n",
    "FRAME_PATH = DATA_PATH+'/Raw_data/'\n",
    "MASK_PATH = DATA_PATH+'/Label_data/'\n",
    "\n",
    "def data_gen(img_folder, mask_folder, batch_size):\n",
    "    c = 0\n",
    "    n = os.listdir(img_folder) #List of training images\n",
    "    random.shuffle(n)\n",
    "  \n",
    "    while (True):\n",
    "        img = np.zeros((batch_size, 360, 640, 1)).astype('float')\n",
    "        mask = np.zeros((batch_size, 360, 640, 1)).astype('float')\n",
    "\n",
    "    for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n",
    "\n",
    "        train_img = cv2.imread(img_folder+'/'+n[i])/255.\n",
    "        train_img =  cv2.resize(train_img, (360, 640))# Read an image from folder and resize\n",
    "      \n",
    "        img[i-c] = train_img #add to array - img[0], img[1], and so on.\n",
    "                                                   \n",
    "\n",
    "        train_mask = cv2.imread(mask_folder+'/'+n[i], cv2.IMREAD_GRAYSCALE)/255.\n",
    "        train_mask = cv2.resize(train_mask, (360, 640))\n",
    "        train_mask = train_mask.reshape(360, 640, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n",
    "\n",
    "        mask[i-c] = train_mask\n",
    "\n",
    "    c+=batch_size\n",
    "    \n",
    "    if(c+batch_size>=len(os.listdir(img_folder))):\n",
    "        c=0\n",
    "        random.shuffle(n)\n",
    "                  # print \"randomizing again\"\n",
    "    yield img, mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_frame_path = DATA_PATH+'/train_frames/'\n",
    "train_mask_path = DATA_PATH+'/train_masks/'\n",
    "\n",
    "val_frame_path = DATA_PATH+'/val_frames/'\n",
    "val_mask_path = DATA_PATH+'/val_masks/'\n",
    "\n",
    "# Train the model\n",
    "train_gen = data_gen(train_frame_path,train_mask_path, batch_size = 32)\n",
    "val_gen = data_gen(val_frame_path,val_mask_path, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|) = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "\n",
    "def jaccard_loss(y_true, y_pred):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 1080, 3)\n",
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "# load the image from disk\n",
    "image = cv2.imread(train_frame_path+img_path[0])\n",
    "# loop over the rotation angles\n",
    "'''\n",
    "for angle in np.arange(0, 360, 15):\n",
    "    rotated = imutils.rotate(image, angle)\n",
    "    cv2.imshow(\"Rotated (Problematic)\", rotated)\n",
    "    cv2.waitKey(0)\n",
    "    '''\n",
    "# loop over the rotation angles again, this time ensuring\n",
    "# no part of the image is cut off\n",
    "rotated = imutils.rotate_bound(image, 90)\n",
    "cv2.imshow(\"Rotated (Correct)\", rotated)\n",
    "print(rotated.shape)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 4s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.2639 - accuracy: 0.9188 - val_loss: 0.0603 - val_accuracy: 0.9809\n",
      "Epoch 2/12\n",
      "11392/60000 [====>.........................] - ETA: 51s - loss: 0.1020 - accuracy: 0.9702"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-210029f2541c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m           validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test loss:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_test))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sidewalk detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
