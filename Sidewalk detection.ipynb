{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sidewalk detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP0xzKZFMDk0aPKrEbcmWUl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"eyEK8AEZ3Tl_","colab_type":"code","outputId":"ae9db1f7-53ab-429d-f2ed-fd3e62b27a3e","executionInfo":{"status":"ok","timestamp":1584353265606,"user_tz":-420,"elapsed":82184,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"source":["#Upgrade to tensorflow2.x\n","!pip install --upgrade tensorflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n","\u001b[K     |████████████████████████████████| 421.8MB 38kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n","Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n","Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n","Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n","Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n","Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n","Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n","Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n","Collecting tensorboard<2.2.0,>=2.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 49.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n","Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n","\u001b[K     |████████████████████████████████| 450kB 56.3MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n","Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\n","Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.7.2)\n","Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (45.2.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.21.0)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\n","Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\n","Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.1)\n","Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\n","Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\n","Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.3)\n","Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\n","Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\n","Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FV7QBfOT_LT2","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","import sklearn\n","from sklearn.metrics import jaccard_score\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, concatenate\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Reshape, Flatten\n","# from tensorflow.keras.utils import np_utils\n","# from tensorflow.keras.callbacks import ModelCheckpoint\n","# from tensorflow.keras.callbacks import CSVLogger\n","# from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import metrics\n","\n","import numpy as np\n","import os\n","import cv2\n","import imutils\n","import random\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import requests\n","import shutil\n","import json\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aofEOchw_6RM","colab_type":"code","outputId":"d745b7a1-473f-4e6b-a155-d86e40a330e1","executionInfo":{"status":"ok","timestamp":1584270393513,"user_tz":-420,"elapsed":4718,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(tf.__version__)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TelqndhaA8dY","colab_type":"code","outputId":"53b70161-4938-4123-970e-a0bb7867f23e","executionInfo":{"status":"ok","timestamp":1584265487644,"user_tz":-420,"elapsed":552,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(os.getcwd())\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Lj0w-ej6nnQK","colab_type":"code","outputId":"294331d8-d649-4e9f-afb7-2cef1d507027","executionInfo":{"status":"ok","timestamp":1584355317275,"user_tz":-420,"elapsed":2931,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","!ls /content/drive/My\\ Drive/JSTP"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"," 20191029_125129.mp4   test_frames   train_frames   val_frames\n","'JSTP slide.mp4'       test_masks    train_masks    val_masks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MWHO9ugPnmQv","colab_type":"code","outputId":"3a9a2584-53a6-41a8-ed05-efc50617f27f","executionInfo":{"status":"ok","timestamp":1584268377470,"user_tz":-420,"elapsed":793,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":[""],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['20191029_125129.mp4',\n"," 'JSTP slide.mp4',\n"," 'train_masks',\n"," 'test_masks',\n"," 'train_frames',\n"," 'val_masks',\n"," 'val_frames',\n"," 'test_frames']"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"gDeiOnA8oV_i","colab_type":"code","outputId":"e9ad47ea-60fa-4381-ea41-cd92f53bacfa","executionInfo":{"status":"ok","timestamp":1584266710938,"user_tz":-420,"elapsed":4810,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":[""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Copying file://adc.json [Content-Type=application/json]...\n","/ [0 files][    0.0 B/  2.6 KiB]                                                \rAccessDeniedException: 403 The project to be billed is associated with an absent billing account.\n","cat: /train_frames: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wT8-88c9ifXl","colab_type":"code","outputId":"3094e68e-1577-4b03-c081-3e2774e286b2","executionInfo":{"status":"ok","timestamp":1584355353331,"user_tz":-420,"elapsed":31837,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["DATA_PATH = 'drive/My Drive/JSTP'\n","\n","train_frame_path = DATA_PATH+'/train_frames/'\n","train_mask_path = DATA_PATH+'/train_masks/'\n","\n","val_frame_path = DATA_PATH+'/val_frames/'\n","val_mask_path = DATA_PATH+'/val_masks/'\n","\n","img_path = os.listdir(train_frame_path)\n","mask_path = os.listdir(train_mask_path)\n","random.shuffle(img_path)\n","random.shuffle(mask_path)\n","\n","train_img = np.zeros((50, 640, 360, 1)).astype('float')\n","train_mask = np.zeros((50, 640, 360, 1)).astype('float')\n","\n","for i in range(0, 50): #initially from 0 to 16, c = 0. \n","        \n","    train_img1 = cv2.imread(train_frame_path+img_path[i],0)/255.\n","    \n","    if train_img1.shape != (1920,1080):\n","        train_img1 = imutils.rotate_bound(train_img1, 90)\n","        \n","    train_img1 =  cv2.resize(train_img1, (360, 640))# Read an image from folder and resize\n","    train_img1 = train_img1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n","    train_img[i] = train_img1 #add to array - img[0], img[1], and so on.\n","        \n","    train_mask1 = cv2.imread(train_mask_path+mask_path[i], cv2.IMREAD_GRAYSCALE)/255.\n","    if train_mask1.shape != (1920,1080): train_mask1 = imutils.rotate_bound(train_mask1, 90)\n","\n","    train_mask1 = cv2.resize(train_mask1, (360, 640))\n","\n","    train_mask1 = train_mask1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n","\n","    train_mask[i] = train_mask1\n","    \n","# Validation set\n","    \n","img_path = os.listdir(val_frame_path)\n","mask_path = os.listdir(val_mask_path)\n","val_img = np.zeros((10, 640, 360, 1)).astype('float')\n","val_mask = np.zeros((10, 640, 360, 1)).astype('float')\n","\n","for i in range(0, 10): #initially from 0 to 16, c = 0. \n","        \n","    val_img1 = cv2.imread(val_frame_path+img_path[i],0)/255.\n","    \n","    if val_img1.shape != (1920,1080): \n","        val_img1 = imutils.rotate_bound(val_img1, 90)\n","        \n","    val_img1 =  cv2.resize(val_img1, (360, 640))# Read an image from folder and resize\n","    val_img1 = val_img1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n","    val_img[i] = val_img1 #add to array - img[0], img[1], and so on.\n","        \n","    val_mask1 = cv2.imread(val_mask_path+mask_path[i], cv2.IMREAD_GRAYSCALE)/255.\n","    if val_mask1.shape != (1920,1080): val_mask1 = imutils.rotate_bound(val_mask1, 90)\n","\n","    val_mask1 = cv2.resize(val_mask1, (360, 640))\n","\n","    val_mask1 = val_mask1.reshape(640, 360, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n","\n","    val_mask[i] = val_mask1\n","    \n","'''\n","def data_gen(img_folder, mask_folder):\n","    n = os.listdir(img_folder) #List of training images\n","    random.shuffle(n)\n","    \n","    print(n)\n","    \n","    img = np.zeros(50, 360, 640, 1).astype('float')\n","    mask = np.zeros(50, 360, 640, 1).astype('float')\n","    print(img,mask)\n","    for i in range(0, 50): #initially from 0 to 16, c = 0. \n","        \n","        train_img = cv2.imread(img_folder+n[i])/255.\n","        train_img =  cv2.resize(train_img, (360, 640))# Read an image from folder and resize\n","      \n","        img[i] = train_img #add to array - img[0], img[1], and so on.\n","        \n","        print(img[i])\n","        \n","        train_mask = cv2.imread(mask_folder+n[i], cv2.IMREAD_GRAYSCALE)/255.\n","        train_mask = cv2.resize(train_mask, (360, 640))\n","        train_mask = train_mask.reshape(360, 640, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\n","\n","        mask[i] = train_mask\n","    \n","    yield img, mask\n","    \n","'''\n"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ndef data_gen(img_folder, mask_folder):\\n    n = os.listdir(img_folder) #List of training images\\n    random.shuffle(n)\\n    \\n    print(n)\\n    \\n    img = np.zeros(50, 360, 640, 1).astype('float')\\n    mask = np.zeros(50, 360, 640, 1).astype('float')\\n    print(img,mask)\\n    for i in range(0, 50): #initially from 0 to 16, c = 0. \\n        \\n        train_img = cv2.imread(img_folder+n[i])/255.\\n        train_img =  cv2.resize(train_img, (360, 640))# Read an image from folder and resize\\n      \\n        img[i] = train_img #add to array - img[0], img[1], and so on.\\n        \\n        print(img[i])\\n        \\n        train_mask = cv2.imread(mask_folder+n[i], cv2.IMREAD_GRAYSCALE)/255.\\n        train_mask = cv2.resize(train_mask, (360, 640))\\n        train_mask = train_mask.reshape(360, 640, 1) # Add extra dimension for parity with train_img size [512 * 512 * 3]\\n\\n        mask[i] = train_mask\\n    \\n    yield img, mask\\n    \\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"KcDAqCvY4N_n","colab_type":"code","colab":{}},"source":["model = Sequential()\n","\n","\n","#1st Layer\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","#1st Layer\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","#1st Layer\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","\n","#Upsampling Part\n","model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","\n","#Upsampling Part\n","model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","\n","#Upsampling Part\n","model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","\n","#Upsampling Part\n","model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","\n","#Upsampling Part\n","model.add(UpSampling2D(size=(2, 2), data_format=None, interpolation='nearest'))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 6), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 10), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","model.add(Conv2D(64, (17, 6), activation='relu', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))\n","model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","\n","model.add(Conv2D(1, (1, 1), activation='sigmoid', kernel_initializer='he_uniform', input_shape=(640, 360, 1)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jbYonz1M8oeA","colab_type":"code","outputId":"721a845c-d169-49f6-db2f-d201acef8e07","executionInfo":{"status":"ok","timestamp":1584355366584,"user_tz":-420,"elapsed":1018,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["(model.summary())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_19 (Conv2D)           (None, 624, 351, 64)      10944     \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 624, 351, 64)      256       \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 608, 342, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 608, 342, 64)      256       \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 304, 171, 64)      0         \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 288, 162, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 288, 162, 64)      256       \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 272, 153, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_21 (Batc (None, 272, 153, 64)      256       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 136, 76, 64)       0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 120, 67, 64)       696384    \n","_________________________________________________________________\n","batch_normalization_22 (Batc (None, 120, 67, 64)       256       \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 104, 58, 64)       696384    \n","_________________________________________________________________\n","batch_normalization_23 (Batc (None, 104, 58, 64)       256       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 52, 29, 64)        0         \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 104, 58, 64)       0         \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 88, 49, 64)        696384    \n","_________________________________________________________________\n","batch_normalization_24 (Batc (None, 88, 49, 64)        256       \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 72, 40, 64)        696384    \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 72, 40, 64)        256       \n","_________________________________________________________________\n","up_sampling2d_6 (UpSampling2 (None, 144, 80, 64)       0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 128, 71, 64)       696384    \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 128, 71, 64)       256       \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 112, 62, 64)       696384    \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 112, 62, 64)       256       \n","_________________________________________________________________\n","up_sampling2d_7 (UpSampling2 (None, 224, 124, 64)      0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 208, 115, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 208, 115, 64)      256       \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 192, 106, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 192, 106, 64)      256       \n","_________________________________________________________________\n","up_sampling2d_8 (UpSampling2 (None, 384, 212, 64)      0         \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 368, 203, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 368, 203, 64)      256       \n","_________________________________________________________________\n","conv2d_32 (Conv2D)           (None, 352, 194, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 352, 194, 64)      256       \n","_________________________________________________________________\n","up_sampling2d_9 (UpSampling2 (None, 704, 388, 64)      0         \n","_________________________________________________________________\n","conv2d_33 (Conv2D)           (None, 688, 379, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 688, 379, 64)      256       \n","_________________________________________________________________\n","conv2d_34 (Conv2D)           (None, 672, 374, 64)      417856    \n","_________________________________________________________________\n","batch_normalization_33 (Batc (None, 672, 374, 64)      256       \n","_________________________________________________________________\n","conv2d_35 (Conv2D)           (None, 656, 365, 64)      696384    \n","_________________________________________________________________\n","batch_normalization_34 (Batc (None, 656, 365, 64)      256       \n","_________________________________________________________________\n","conv2d_36 (Conv2D)           (None, 640, 360, 64)      417856    \n","_________________________________________________________________\n","batch_normalization_35 (Batc (None, 640, 360, 64)      256       \n","_________________________________________________________________\n","conv2d_37 (Conv2D)           (None, 640, 360, 1)       65        \n","=================================================================\n","Total params: 11,297,089\n","Trainable params: 11,294,785\n","Non-trainable params: 2,304\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ceS4rp0VGwWt","colab_type":"code","outputId":"6a4a7733-db3b-4e30-8162-8521752d9c21","executionInfo":{"status":"error","timestamp":1584355377059,"user_tz":-420,"elapsed":8288,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","\n","with strategy.scope():\n","  model = model\n","  model.compile(\n","      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, ),\n","      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","      metrics=['accuracy'])\n","\n","model.fit(\n","    train_img.astype(np.float32), train_mask.astype(np.float32),\n","    epochs=17,\n","    steps_per_epoch=60,\n","    validation_data=(val_img.astype(np.float32), val_mask.astype(np.float32)),\n","    validation_freq=17\n",")\n","\n","model.save_weights('./sidewalk_weight.h5', overwrite=True)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: 10.1.124.226:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: 10.1.124.226:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-88205ea0fb57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       metrics=['accuracy'])\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m model.fit(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;34m'with strategy.scope():\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0;34m'  model=_create_model()\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m                 '  model.compile(...)'% (v, strategy))\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable (<tf.Variable 'conv2d_19/kernel:0' shape=(17, 10, 1, 64) dtype=float32>) was not created in the distribution strategy scope of (<tensorflow.python.distribute.tpu_strategy.TPUStrategy object at 0x7fbd5616fda0>). It is most likely due to not all layers or the model or optimizer being created outside the distribution strategy scope. Try to make sure your code looks similar to the following.\nwith strategy.scope():\n  model=_create_model()\n  model.compile(...)"]}]},{"cell_type":"code","metadata":{"id":"8cCvq0UR49ln","colab_type":"code","outputId":"29b29534-fccc-48a9-b0cd-1b0313d4f5f0","executionInfo":{"status":"ok","timestamp":1584272567758,"user_tz":-420,"elapsed":6662,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: 10.93.215.194:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: 10.93.215.194:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7fbe1b7a0c88>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"QTfPsHaSAk-w","colab_type":"code","colab":{}},"source":["strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","with strategy.scope():\n","  model = create_model()\n","  model.compile(optimizer='adam',\n","                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                metrics=['sparse_categorical_accuracy'])\n","  \n","train_dataset, test_dataset = get_dataset()\n","\n","model.fit(train_dataset,\n","          epochs=5,\n","          validation_data=test_dataset)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSW6hya8D-y4","colab_type":"code","outputId":"a044bd93-d56b-4e21-ef7c-50b114821ac9","executionInfo":{"status":"ok","timestamp":1584355804352,"user_tz":-420,"elapsed":2232,"user":{"displayName":"Krittiphong Manachamni","photoUrl":"","userId":"06767633234992281523"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!git remote add gdrive /drive/My\\ drive/github_project/.git"],"execution_count":13,"outputs":[{"output_type":"stream","text":["fatal: not a git repository (or any of the parent directories): .git\n"],"name":"stdout"}]}]}